[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to the British Social Attitudes Survey",
    "section": "",
    "text": "Introduction\nThis repository contains the Quarto source files of the practical exercises for the Introduction to Social Attitudes Surveys UKDS Data Skills Module.\nA key aim of the BSA is to track the views and opinions of the public on national issues over time. The BSA questionnaire has core questions that are repeated in most years. These cover different topics such as politics, welfare, poverty, health, education, equalities, and employment. In addition, the interview questionnaire consists of various background and demographic questions. The rest of the questionnaire includes a series of non-core questions (modules) on a number of social, political, economic and moral topics, which are included in the survey less frequently.\nDirect links to the HTML pages of the exercises on GitHub Pages:\n\nR version:\n\nBasic population estimates with BSA data using R \nSurvey design informed inference with BSA data using R\n\nSPSS version:\n\nBasic population estimates with BSA data using SPSS \n Survey design informed inference with BSA data using SPSS",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "infer_w_survey_design_usingR.html",
    "href": "infer_w_survey_design_usingR.html",
    "title": "Using R with weights and survey design variables",
    "section": "",
    "text": "This exercise is part of the ‘Introduction to the British Social Attitudes Survey (BSA)’ online module. In this exercise, we will practice statistical inference with data from the British Social Attitudes Survey (BSA) 2017 using weights and survey design variables.\nPlease note that at the time of writing this document only some of the BSA editions include survey design variables. For more information about inference from social surveys, including cases where weights and/or survey design variables are not available, please consult our guidelines.\nAnswers to the questions asked throughout the exercise can be found at the end of the page.\n\nGetting started\nData can be downloaded from the UK Data Service website following registration. Download the compressed folder, unzip and save it somewhere accessible on your computer.\nThe examples below assume that the dataset has been saved in a new folder named UKDS on your Desktop (Windows computers). The path would typically be C:\\Users\\YOUR_USER_NAME\\Desktop\\UKDS. Feel free to change it to the location that best suits your needs\nThe code below will need to be adjusted in order to match the location of the data on your computer.\nWe begin by loading the R packages needed for the exercise and set the working directory.\n\nlibrary(dplyr) ### Data manipulation functions\nlibrary(haven) ### Functions for importing data from commercial packages\nlibrary(Hmisc) ### Extra statistical functions\nlibrary(survey) ### Survey design functions\n\n### Setting up the working directory\n### Change the setwd() command  to match the location of the data on your computer \n### if required \n\nsetwd(\"C:\\Users\\Your_Username_here\\\")\n\ngetwd()\n\n# Opening the BSA dataset in SPSS format\nbsa17&lt;-read_spss(\"data/UKDA-8450-spss/spss/spss25/bsa2017_for_ukda.sav\")\n\n[1] C:\\Users\\Your_Username_here\\\n\n\n1. Identifying the survey design and variables\nWe first need to find out about the survey design that was used in the BSA 2017, and the design variables available in the dataset. Such information can usually be found in the documentation that comes together with the data under the mrdoc/pdf folder or in the data catalogue pages for the data on the UK Data Service website.\nQuestion 1\nWhat is the design that was used in this survey (i.e. how many sampling stages were there, and what were the units sampled). What were the primary sampling units; the strata (if relevant)?\nNow that we are a bit more familiar with the way the survey was designed, we need to try and identify the design variables we can include when producing estimates. The information can usually be found in the data documentation or the data dictionary available in the BSA documentation. \nQuestion 2\nWhat survey design variables are available? Are there any that are missing – if so which ones? What is the name of the weights variables?\n\n\n2. Specifying the survey design\nWe need to tell R about the survey design. In practice this often means specifying the units selected at the initial sampling stage ie the Primary Sampling Units, as well as the strata. This is achieved with the svydesign() command. In effect this command creates a copy of the dataset with the survey design information attached, that can then subsequently be used for further estimation.\n\nbsa17.s&lt;-svydesign(ids=~Spoint,       ### Primary Sampling Units\n                   strata=~StratID,   ### Strata if stratified design\n                   weights=~WtFactor, ### Weights\n                   data=bsa17)        ### The dataset\nclass(bsa17.s)\n\n[1] \"survey.design2\" \"survey.design\" \n\nsummary(bsa17.s) ### Warning: very long output\n\nStratified 1 - level Cluster Sampling design (with replacement)\nWith (372) clusters.\nsvydesign(ids = ~Spoint, strata = ~StratID, weights = ~WtFactor, \n    data = bsa17)\nProbabilities:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2645  0.8288  1.0983  1.2386  1.6236  3.3318 \nStratum Sizes: \n           101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\nobs         18  22  30  18  16  21  22  37  10  22  19  35  23  19  19  21  25\ndesign.PSU   2   2   3   2   2   2   2   3   2   3   2   3   2   2   2   2   2\nactual.PSU   2   2   3   2   2   2   2   3   2   3   2   3   2   2   2   2   2\n           118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\nobs         12  12  32  40  25  21  23  26  23  18  34  23  20  29  39  19  30\ndesign.PSU   2   2   3   3   3   2   2   2   3   2   2   2   2   3   3   2   3\nactual.PSU   2   2   3   3   3   2   2   2   3   2   2   2   2   3   3   2   3\n           135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151\nobs         20  10  21  12  26  16  20  17  21  24  30  30  18  29  24  19  28\ndesign.PSU   2   2   2   2   3   2   2   2   2   3   2   3   2   3   2   3   2\nactual.PSU   2   2   2   2   3   2   2   2   2   3   2   3   2   3   2   3   2\n           152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168\nobs         18   8  23  33  14  23  17  39  13  22  16  19  21  18  26  13  14\ndesign.PSU   2   2   2   3   2   2   2   3   2   2   2   2   2   2   3   2   2\nactual.PSU   2   2   2   3   2   2   2   3   2   2   2   2   2   2   3   2   2\n           169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\nobs         22  20   8  22  31  22  24  19  38  20  29  24  29  21  23  32  36\ndesign.PSU   2   2   2   2   2   2   2   2   3   2   2   2   3   2   2   3   3\nactual.PSU   2   2   2   2   2   2   2   2   3   2   2   2   3   2   2   3   3\n           186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202\nobs         24  22  43  38  38  47  34  15  22  35  17  20  20  21  21  43  35\ndesign.PSU   3   2   3   3   3   3   3   2   2   3   2   2   2   2   3   3   3\nactual.PSU   3   2   3   3   3   3   3   2   2   3   2   2   2   2   3   3   3\n           203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\nobs         28  25  19  18  28  15  21  30  24  33  24  22  30  24  44  18  26\ndesign.PSU   3   3   2   2   2   2   2   2   2   3   2   2   3   2   3   2   2\nactual.PSU   3   3   2   2   2   2   2   2   2   3   2   2   3   2   3   2   2\n           220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236\nobs         22  28  20  27  34  33  41  24  23  26  17  23  36  20  45  32  27\ndesign.PSU   2   2   2   3   2   3   3   2   2   2   2   2   3   2   3   3   3\nactual.PSU   2   2   2   3   2   3   3   2   2   2   2   2   3   2   3   3   3\n           237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253\nobs         33  25  39  31  29  33  20  43  22  24  26  29  37  22  27  25  43\ndesign.PSU   3   3   3   3   2   2   2   3   2   2   2   2   3   2   2   2   3\nactual.PSU   3   3   3   3   2   2   2   3   2   2   2   2   3   2   2   2   3\n           254 255 256 257 258 259\nobs          7  32  26  25  28  35\ndesign.PSU   2   3   2   2   2   3\nactual.PSU   2   3   2   2   2   3\nData variables:\n  [1] \"Sserial\"              \"Spoint\"               \"StratID\"             \n  [4] \"WtFactor\"             \"OldWt\"                \"GOR_ID\"              \n  [7] \"ABCVer\"               \"Country\"              \"househlde\"           \n [10] \"hhtypee\"              \"Rsex\"                 \"RAgeE\"               \n [13] \"RAgeCat\"              \"RAgeCat2\"             \"RAgecat3\"            \n [16] \"RAgecat4\"             \"RAgecat5\"             \"RSexAge\"             \n [19] \"RSexAge2\"             \"MarStat\"              \"Married\"             \n [22] \"legmarste\"            \"ChildHh\"              \"nch415e\"             \n [25] \"nch318e\"              \"hhch04e\"              \"hhch511e\"            \n [28] \"hhch1215e\"            \"hhch1617e\"            \"rch04e\"              \n [31] \"rch511e\"              \"rch1215e\"             \"rch1617e\"            \n [34] \"ownche\"               \"reconacte\"            \"RLastJob\"            \n [37] \"seconacte\"            \"Readpap\"              \"WhPaper\"             \n [40] \"paptype\"              \"TVNews\"               \"WebNews\"             \n [43] \"WNwSite1\"             \"WNwSite2\"             \"SMNews\"              \n [46] \"Internet\"             \"IntPers\"              \"MedResI\"             \n [49] \"SupParty\"             \"ClosePty\"             \"PartyIDN\"            \n [52] \"Partyid1\"             \"PartyId2\"             \"PartyID3\"            \n [55] \"PtyAlleg\"             \"Idstrng\"              \"Politics\"            \n [58] \"Coalitin\"             \"ConLabDf\"             \"VoteSyst\"            \n [61] \"ScotPar2\"             \"ECPolicy2\"            \"GovTrust\"            \n [64] \"Monarchy\"             \"MiEcono\"              \"MiCultur\"            \n [67] \"Spend1\"               \"Spend2\"               \"SocSpnd1\"            \n [70] \"SocSpnd2\"             \"SocSpnd3\"             \"SocSpnd4\"            \n [73] \"SocSpnd5\"             \"SocSpnd6\"             \"Dole\"                \n [76] \"TaxSpend\"             \"IncomGap\"             \"SRInc\"               \n [79] \"CMArran\"              \"RBGaran2\"             \"SepInvol\"            \n [82] \"SepServ\"              \"WkMent\"               \"WkPhys\"              \n [85] \"HProbRsp\"             \"PhsRetn\"              \"PhsRecov\"            \n [88] \"MntRetn\"              \"MntRecov\"             \"HCWork21\"            \n [91] \"HCWork22\"             \"HCWork23\"             \"HCWork24\"            \n [94] \"HCWork25\"             \"HCWork26\"             \"HCWork27\"            \n [97] \"HCWork28\"             \"HCWork29\"             \"NatFrEst\"            \n[100] \"FalseBn2\"             \"RepFrau3\"             \"RepWho1\"             \n[103] \"RepWho2\"              \"RepWho3\"              \"RepWho4\"             \n[106] \"RepWho5\"              \"RepWho6\"              \"RepWho7\"             \n[109] \"RepWho8\"              \"RepWho9\"              \"RepWho10\"            \n[112] \"WhyNRep1\"             \"WhyNRep2\"             \"WhyNRep3\"            \n[115] \"WhyNRep4\"             \"WhyNRep5\"             \"WhyNRep6\"            \n[118] \"WhyNRep7\"             \"WhyNRep8\"             \"WhyNRep9\"            \n[121] \"BFPnsh1\"              \"BFPnsh2\"              \"BFPnsh3\"             \n[124] \"BFPnsh4\"              \"BFPnsh5\"              \"BFPnsh6\"             \n[127] \"BFPnsh7\"              \"BFPnsh8\"              \"BFPnsh9\"             \n[130] \"BFPnsh10\"             \"BFPnsh11\"             \"AwrPB\"               \n[133] \"AdminPn2\"             \"LosofBen\"             \"AwrCRec\"             \n[136] \"GovDoBF\"              \"ImpHDoc\"              \"ImpHPar\"             \n[139] \"ImpHBeha\"             \"ImpHFam\"              \"ImpHEd\"              \n[142] \"ImpHJob\"              \"ImpHNeig\"             \"ImpHArea\"            \n[145] \"ImpHSafe\"             \"RespoHl2\"             \"HomsBult\"            \n[148] \"YSBEmpl\"              \"YSBTrans\"             \"YSBGreen\"            \n[151] \"YSBSch\"               \"YSBAfRnt\"             \"YSBAfOwn\"            \n[154] \"YSBDesig\"             \"YSBShops\"             \"YSBMedic\"            \n[157] \"YSBLibry\"             \"YSBLeis\"              \"YSBFinan\"            \n[160] \"YSBOther\"             \"YSBDeps\"              \"YSBNone\"             \n[163] \"HousGSD\"              \"Buldres\"              \"EdSpnd1c\"            \n[166] \"EdSpnd2c\"             \"VocVAcad\"             \"ATTD151\"             \n[169] \"ATTD152\"              \"ATTD153\"              \"ATTD154\"             \n[172] \"ATTD155\"              \"ATTD156\"              \"ATTD157\"             \n[175] \"ATTD158\"              \"ATTD81\"               \"ATTD82\"              \n[178] \"ATTD83\"               \"ATTD84\"               \"ATTD85\"              \n[181] \"ATTD86\"               \"ATTD87\"               \"ATTD88\"              \n[184] \"GCSEFur\"              \"GCSEWrk\"              \"ALevFur\"             \n[187] \"ALevWrk\"              \"HEdOpp\"               \"ChLikUn2\"            \n[190] \"HEFee\"                \"FeesUni\"              \"FeesSub\"             \n[193] \"Himp\"                 \"PREVFR\"               \"TRFPB6U\"             \n[196] \"TRFPB9U\"              \"TrfPb10u\"             \"TrfConc1\"            \n[199] \"DRIVE\"                \"carnume\"              \"CycDang\"             \n[202] \"Bikeown2\"             \"BikeRid\"              \"TRAVEL1\"             \n[205] \"TRAVEL2\"              \"TRAVEL3\"              \"TRAVEL4a\"            \n[208] \"TRAVEL6\"              \"airtrvle\"             \"CCTrans1\"            \n[211] \"CCTrans2\"             \"CCTrans3\"             \"CCTrans4\"            \n[214] \"CCTrans5\"             \"CCTrans6\"             \"CCTrans7\"            \n[217] \"CCTrans8\"             \"CCTrans9\"             \"CCALowE\"             \n[220] \"CCACar\"               \"CCAPLANE\"             \"CCBELIEV\"            \n[223] \"EUBrld\"               \"EUExInf2\"             \"EUExUne2\"            \n[226] \"EUExIm2\"              \"EUExEco2\"             \"EUImpSov\"            \n[229] \"LeavEUI\"              \"EUconte\"              \"EUcontu\"             \n[232] \"EUconth\"              \"EULtop1\"              \"EULtop2\"             \n[235] \"EULtop3\"              \"NHSSat\"               \"WhySat1\"             \n[238] \"WhySat2\"              \"WhySat3\"              \"WhySat4\"             \n[241] \"WhySat5\"              \"WhySat6\"              \"WhySat7\"             \n[244] \"WhySat8\"              \"WhySat9\"              \"WhySat10\"            \n[247] \"WhyDis1\"              \"WhyDis2\"              \"WhyDis3\"             \n[250] \"WhyDis4\"              \"WhyDis5\"              \"WhyDis6\"             \n[253] \"WhyDis7\"              \"WhyDis8\"              \"WhyDis9\"             \n[256] \"WhyDis10\"             \"GPSat\"                \"DentSat\"             \n[259] \"InpatSat\"             \"OutpaSat\"             \"AESat\"               \n[262] \"CareSat3\"             \"NHSFProb\"             \"NHS5yrs\"             \n[265] \"NHSNx5Yr\"             \"NHSAcc\"               \"NHSImp\"              \n[268] \"AEtravel\"             \"CareNee2\"             \"PaySocia\"            \n[271] \"CarePa2\"              \"SocFutur\"             \"Tranneed\"            \n[274] \"Prejtran\"             \"PMS\"                  \"HomoSex\"             \n[277] \"SSRel\"                \"RSuperv\"              \"rocsect2e\"           \n[280] \"REmpWork\"             \"REmpWrk2\"             \"SNumEmp\"             \n[283] \"WkJbTim\"              \"ESrJbTim\"             \"SSrJbTim\"            \n[286] \"WkJbHrsI\"             \"ExPrtFul\"             \"EJbHrCaI\"            \n[289] \"SJbHrCaI\"             \"RPartFul\"             \"S2PartFl\"            \n[292] \"Remplyee\"             \"UnionSA\"              \"TUSAEver\"            \n[295] \"NPWork10\"             \"RES2010\"              \"RES2000\"             \n[298] \"SLastJb2\"             \"S2Employ\"             \"S2Superv\"            \n[301] \"S2ES2010\"             \"S2ES2000\"             \"rjbtype\"             \n[304] \"REconSum\"             \"REconPos\"             \"RNSEGGrp\"            \n[307] \"RNSocCl\"              \"RNSSECG\"              \"RClass\"              \n[310] \"RClassGp\"             \"RSIC07GpE\"            \"seconsum\"            \n[313] \"S2NSEGGp\"             \"S2NSSECG\"             \"S2NSocCl\"            \n[316] \"S2Class\"              \"S2ClassG\"             \"WAGMIN\"              \n[319] \"RESPPAY\"              \"TRCURJM\"              \"TRCURJN\"             \n[322] \"TRMRSJM\"              \"TRMRSJN\"              \"TRDIFJM\"             \n[325] \"TRDIFJN\"              \"PHOURS\"               \"REGHOUR\"             \n[328] \"WRKCON\"               \"JBMRESP\"              \"JBMWH1\"              \n[331] \"JBMWH2\"               \"JBMWH3\"               \"JBMWH4\"              \n[334] \"JBMWH5\"               \"JBMWH6\"               \"JBMWH7\"              \n[337] \"JBMWH8\"               \"FLEXHRS\"              \"MgCWld\"              \n[340] \"MgMWld\"               \"ChgAsJb1\"             \"ChgAsJb2\"            \n[343] \"ChgAsJb3\"             \"ChgJbTim\"             \"RetExp\"              \n[346] \"RetExpb\"              \"DVRetAge\"             \"PenKnow2\"            \n[349] \"RPenSrc1\"             \"RPenSrc2\"             \"RPenSrc3\"            \n[352] \"whrbrne\"              \"NatIdGB\"              \"NatId\"               \n[355] \"tenure2e\"             \"RentPrf1\"             \"HAWhat\"              \n[358] \"HAgdbd\"               \"HANotFM\"              \"LikeHA\"              \n[361] \"HAYwhy\"               \"HANwhy\"               \"HsDepnd\"             \n[364] \"ResPres\"              \"ReligSum\"             \"RlFamSum\"            \n[367] \"ChAttend\"             \"bestnatu2\"            \"raceori4\"            \n[370] \"DisNew2\"              \"DisAct\"               \"DisActDV\"            \n[373] \"Knowdis1\"             \"Knowdis2\"             \"Knowdis3\"            \n[376] \"Knowdis4\"             \"Knowdis5\"             \"Knowdis6\"            \n[379] \"Knowdis7\"             \"DisPrj\"               \"Dis100\"              \n[382] \"tea3\"                 \"HEdQual\"              \"HEdQual2\"            \n[385] \"HEdQual3\"             \"EUIdent\"              \"BritID2\"             \n[388] \"Voted\"                \"Vote\"                 \"EURefV2\"             \n[391] \"EUVOTWHO\"             \"EURefb\"               \"AnyBN3\"              \n[394] \"MainInc5\"             \"HHIncD\"               \"HHIncQ\"              \n[397] \"REarnD\"               \"REarnQ\"               \"SelfComp\"            \n[400] \"knwbdri\"              \"knwexec\"              \"knwclea\"             \n[403] \"knwhair\"              \"knwhr\"                \"knwlaw\"              \n[406] \"knwmech\"              \"knwnurs\"              \"knwpol\"              \n[409] \"knwtchr\"              \"incdiffs\"             \"incdsml\"             \n[412] \"govldif\"              \"socblaz\"              \"whoprvhc\"            \n[415] \"whoprvca\"             \"actgrp\"               \"actpol\"              \n[418] \"actchar\"              \"govnosa2\"             \"hhldjob\"             \n[421] \"hhmsick\"              \"hdown\"                \"hadvice\"             \n[424] \"hsococc\"              \"hlpmny\"               \"hlpjob\"              \n[427] \"hlpadmin\"             \"hlplive\"              \"hlpill\"              \n[430] \"lckcomp\"              \"isolate\"              \"leftout\"             \n[433] \"peopadvt\"             \"peoptrst\"             \"trstcrts\"            \n[436] \"trstprc\"              \"helpeldy\"             \"helpslf1\"            \n[439] \"helpfrnd\"             \"fampress\"             \"reltdemd\"            \n[442] \"ffrangr\"              \"eatout\"               \"newfrnd\"             \n[445] \"pplcont\"              \"pplftf\"               \"parcont\"             \n[448] \"sibcon2\"              \"chdcon2\"              \"othcont\"             \n[451] \"frndcont\"             \"contint\"              \"ltsgnhth\"            \n[454] \"depres\"               \"diffpile\"             \"acgoals\"             \n[457] \"lifesat2\"             \"makeem\"               \"langgs\"              \n[460] \"helpslf2\"             \"payback\"              \"domconv\"             \n[463] \"sitwhr\"               \"hmecont\"              \"religcon\"            \n[466] \"spseedu\"              \"ben3000\"              \"ben3000d\"            \n[469] \"falcatch\"             \"uniaff\"               \"unicar\"              \n[472] \"bothearn\"             \"sexrole\"              \"womworka\"            \n[475] \"womworkb\"             \"parlvmf2\"             \"gendwrk\"             \n[478] \"gendmath\"             \"gendcomp\"             \"sxbstrm\"             \n[481] \"sxbintm\"              \"sxbstrw\"              \"sxbintw\"             \n[484] \"sxblaw\"               \"sxbprov\"              \"sxboffb\"             \n[487] \"sxbnoone\"             \"sxboth\"               \"sxbcc\"               \n[490] \"carwalk2\"             \"carbus2\"              \"carbike2\"            \n[493] \"shrtjrn\"              \"plnallow\"             \"plnterm\"             \n[496] \"plnenvt\"              \"plnuppri\"             \"cartaxhi\"            \n[499] \"carallow\"             \"carreduc\"             \"carnod2\"             \n[502] \"carenvdc\"             \"resclose\"             \"res20mph\"            \n[505] \"resbumps\"             \"ddnodrv\"              \"ddnklmt\"             \n[508] \"specamsl\"             \"specammo\"             \"specamtm\"            \n[511] \"speedlim\"             \"speavesc\"             \"mobdsafe\"            \n[514] \"mobddang\"             \"mobdban\"              \"mobdlaw\"             \n[517] \"eutrdmv\"              \"consvfa\"              \"labrfa\"              \n[520] \"libdmfa\"              \"ukipfa\"               \"rthdswa2\"            \n[523] \"rthdsaw2\"             \"rthdsca2\"             \"rthdssa2\"            \n[526] \"rthdsprd\"             \"eqrdisab\"             \"nhsoutp2\"            \n[529] \"nhsinp2\"              \"bodimr\"               \"bodimop\"             \n[532] \"girlwapp\"             \"tprwrong2\"            \"eulunem\"             \n[535] \"eulimm\"               \"eulecon\"              \"eulwork\"             \n[538] \"eullowi\"              \"eulmlow\"              \"eulnhs\"              \n[541] \"jbernmny\"             \"jbenjoy\"              \"topupchn\"            \n[544] \"topupnch\"             \"topuplpa\"             \"worknow\"             \n[547] \"losejob\"              \"jbgdcurr\"             \"robots\"              \n[550] \"robown\"               \"voteduty\"             \"welfhelp\"            \n[553] \"morewelf\"             \"unempjob\"             \"sochelp\"             \n[556] \"dolefidl\"             \"welffeet\"             \"damlives\"            \n[559] \"proudwlf\"             \"redistrb\"             \"BigBusnn\"            \n[562] \"wealth\"               \"richlaw\"              \"indust4\"             \n[565] \"tradvals\"             \"stifsent\"             \"deathapp\"            \n[568] \"obey\"                 \"wronglaw\"             \"censor\"              \n[571] \"leftrigh\"             \"libauth\"              \"welfare2\"            \n[574] \"libauth2\"             \"leftrig2\"             \"welfgrp\"             \n[577] \"eq_inc_deciles\"       \"eq_inc_quintiles\"     \"eq_bhcinc2_deciles\"  \n[580] \"eq_bhcinc2_quintiles\"\n\n\n\n\n3. Mean age and its 95% confidence interval\nWe can now produce a first set of estimates using this information and compare them with those we would have got without accounting for the survey design. We will compute the average (ie mean) age of respondents in the sample. We will need to use svymean()\n\nsvymean(~RAgeE,bsa17.s)\n\n        mean     SE\nRAgeE 48.313 0.4236\n\n\nBy default svymean() computes the standard error of the mean. We need to\nembed it within confint() in order to get a confidence interval.\n\nconfint(svymean(~RAgeE,bsa17.s)) ### Just the confidence interval...\n\n         2.5 %  97.5 %\nRAgeE 47.48289 49.1433\n\nround(\n  c(\n    svymean(~RAgeE,bsa17.s),\n    confint(svymean(~RAgeE,bsa17.s))\n    ),\n  1) ### ... Or both, rounded\n\nRAgeE             \n 48.3  47.5  49.1 \n\n\nWhat difference would it make to the estimates and 95% CI to compute respectively, an unweighted mean, as well as a weighted mean without accounting for the survey design?\nThere are different ways of computing ‘naive estimates’ in R. Below we demonstrate how to do it ´by hand’ for greater transparency.\nBase R provides a function for computing the variance of a variable: var(). Since we know that:\n\nThe standard deviation of the mean is the square root of its variance\nThe standard error of a sample mean is its standard deviation divided by the square root of the sample size\nA 95% confidence interval is the sample mean respectively minus and plus 1.96 times its standard error. It is then relatively straightforward to compute unweighted and ‘casually weighted’ confidences intervals for the mean.\n\n\n### Unweighted means and CI\nu.m&lt;- mean(bsa17$RAgeE)\nu.se&lt;-sqrt(var(bsa17$RAgeE))/sqrt(length(bsa17$RAgeE))\nu.ci&lt;-c(u.m - 1.96*u.se,u.m + 1.96*u.se)\nround(c(u.m,u.ci),1)\n\n[1] 52.2 51.6 52.8\n\n### Weighted means and CI without survey design\nw.m&lt;- wtd.mean(bsa17$RAgeE,bsa17$WtFactor)\nw.se&lt;-sqrt(wtd.var(bsa17$RAgeE,bsa17$WtFactor))/sqrt(length(bsa17$RAgeE))\nw.ci&lt;-c(w.m - 1.96*w.se,w.m + 1.96*w.se)\nround(c(w.m,w.ci),1)\n\n[1] 48.3 47.7 48.9\n\n\nQuestion 3\nWhat are the consequences of not accounting for the sample design; not using weights and accounting for the sample design when:\n- inferring the mean value of the population age?\n- inferring the uncertainty of our estimate of the population age?\n\n\n4. Computing a proportion and its 95% confidence interval\nWe can now similarly estimate the distribution of a categorical variable in the population by computing proportions (or percentages), for instance, the proportion of people who declare themselves interested in politics. This is the Politics variable. It has five categories that we are going to recode into ‘Significantly’ (interested) and ‘Not’ (significantly), for simplicity.\nThe BSA regards ‘don’t know’ and ‘refusal’ responses as valid but since in this case there is only one ‘don’t know’ and no ‘refusal’, we can safely ignore these categories and recode them as system missing. As before, we prefer using xtabs() over table() as it allows us to ignore unused factor levels.\n\nattr(bsa17$Politics,\"label\")     ### Phrasing of the question\n\n[1] \"How much interest do you have in politics?\"\n\nxtabs(~as_factor(Politics),\n      data=bsa17,\n      drop.unused.levels = T) ### Sample distribution\n\nas_factor(Politics)\n... a great deal,      quite a lot,             some,    not very much, \n              739               982              1179               708 \n or, none at all?        Don`t know \n              379                 1 \n\nbsa17$Politics.s&lt;-ifelse(bsa17$Politics==1 | bsa17$Politics==2,\n                         \"Significantly\",NA)\nbsa17$Politics.s&lt;-ifelse(bsa17$Politics&gt;=3 & bsa17$Politics&lt;=5,\n                         \"Not Interested\",bsa17$Politics.s)\nbsa17$Politics.s&lt;-as.factor(bsa17$Politics.s)\n\nrbind(xtabs(~as_factor(Politics.s),\n      data=bsa17,\n      drop.unused.levels = T) ,\n      round(\n        100*prop.table(\n          xtabs(~as_factor(Politics),\n          data=bsa17,\n          drop.unused.levels = T) \n          ),\n        1)\n)\n\n     ... a great deal, quite a lot,  some, not very much, or, none at all?\n[1,]            2266.0       1721.0 2266.0         1721.0           2266.0\n[2,]              18.5         24.6   29.6           17.8              9.5\n     Don`t know\n[1,]       1721\n[2,]          0\n\n\nChanges in a data frame are not automatically transferred into svydesign objects used for inferences. We therefore need to recreate it each time we create or recode a variable.\n\nrbind(round(xtabs(WtFactor~Politics.s,bsa17),\n            1),\n      round(100*\n              prop.table(\n                xtabs(WtFactor~Politics.s,bsa17))\n            ,1)\n)\n\n     Not Interested Significantly\n[1,]         2270.6        1715.2\n[2,]           57.0          43.0\n\nbsa17.s&lt;-svydesign(ids=~Spoint,      \n                   strata=~StratID, \n                   weights=~WtFactor,\n                   data=bsa17)\n\nrbind(round(svytable(~Politics.s,\n                     bsa17.s),1),\n      round(100*prop.table(\n        svytable(~Politics.s,\n                 bsa17.s)),1)\n)\n\n     Not Interested Significantly\n[1,]         2270.6        1715.2\n[2,]           57.0          43.0\n\n\nAs with the mean of age earlier, we can see that the weighted and unweighted point estimates of the proportion of respondents significantly interested in politics differ, even if slightly, and that weighted point estimates do not differ irrespective of the survey design being accounted for.\nLet us now examine the confidence intervals of these proportions. Traditional statistical software usually compute these without telling us about the underlying computations going on. By contrast, doing this in R requires more coding, but in the process we gain a better understanding of what is actually estimated.\nConfidence intervals for proportion of categorical variables are usually computed as a sequence of binomial/dichotomic estimations – ie one for each category. In R this needs to be specified explicitly via the svyciprop() and I() functions. The former actually computes the proportion and its confidence interval (by default 95%), whereas the latter allows us to define the category we are focusing on (in case of non dichotomic variable).\n\nsvyciprop(~I(Politics.s==\"Significantly\"),\n          bsa17.s)\n\n                                        2.5% 97.5%\nI(Politics.s == \"Significantly\") 0.430 0.411 0.450\n\nround(100*\n        c(prop.table(\n          svytable(~Politics.s,bsa17.s))[2],\nattr(svyciprop(~I(Politics.s==\"Significantly\"),\n               bsa17.s),\"ci\")),1\n)\n\nSignificantly          2.5%         97.5% \n         43.0          41.1          45.0 \n\n\nQuestion 4\nWhat is the proportion of respondents aged 17-34 in the sample, as well as its 95% confidence interval? You can use RAgecat5\n\n\n5. Domain (ie subpopulation) estimates\nComputing estimates for specific groups of a sample (for example the average age of people who reported being interested in politics) is not much more difficult than doing it for the sample as a whole. However doing it as part of an inferential analysis requires some caution. Calculating weighted estimates for a subpopulation, amounts to computing second order estimates ie an estimate for a group whose size needs to be estimated first. Therefore, attempting this while leaving out of the rest of the sample might yield incorrect results. This is why using survey design informed functions is particularly recommended in such cases.\nThe survey package functionsvyby() makes such domain estimation relatively straightforward. For instance, if we would like to compute the mean age of BSA respondents by Government Office Regions, we need to specify:\n\nThe outcome variable whose estimate we want to compute: ie RAgeE\nThe grouping variable(s) GOR_ID\nThe estimate function we are going to use here: svymean, the same as we used before\nAnd the type of type of variance estimation we would like to see displayed ie standard errors or confidence interval\n\n\nbsa17$gor.f&lt;-as_factor(bsa17$GOR_ID)\nbsa17.s&lt;-svydesign(ids=~Spoint, \n                   strata=~StratID, \n                   weights=~WtFactor,\n                   data=bsa17)\n\nround(svyby(~RAgeE,\n            by=~gor.f,\n            svymean,\n            design=bsa17.s,\n            vartype = \"ci\")[-1],1)\n\n                           RAgeE ci_l ci_u\nA North East                46.1 43.6 48.6\nB North West                49.6 47.3 52.0\nD Yorkshire and The Humber  48.0 45.2 50.8\nE East Midlands             48.6 45.9 51.3\nF West Midlands             48.1 45.0 51.2\nG East of England           49.0 46.0 52.0\nH London                    45.0 43.0 46.9\nJ South East                48.0 45.1 50.8\nK South West                53.4 51.5 55.2\nL Wales                     49.1 45.1 53.1\nM Scotland                  47.3 44.7 50.0\n\n\nNote: we used [-1] from the object created by svyby() in order to remove a column with alphanumeric values (the region names), so that we could round the results without getting an error.\nOur inference seem to suggest that the population in London is among the youngest in the country, and that those in the South West are among the oldest – their respective 95% confidence intervals do not overlap. We should not feel so confident about differences between London and the South East for example, as the CIs partially overlap.\nWe can follow a similar approach with proportions: we just need to specify the category of the variable we are interested in as an outcome, for instance respondents who are significantly interested in politics, and replace svymean by svyciprop.\n\nround(\n      100*\n      svyby(~I(Politics.s==\"Significantly\"),\n            by=~gor.f,\n            svyciprop,\n            design=bsa17.s,\n            vartype = \"ci\")[-1],\n            1)\n\n                           I(Politics.s == \"Significantly\") ci_l ci_u\nA North East                                           33.4 26.6 40.9\nB North West                                           42.1 36.3 48.2\nD Yorkshire and The Humber                             35.6 29.1 42.6\nE East Midlands                                        36.9 32.9 41.1\nF West Midlands                                        36.3 31.5 41.5\nG East of England                                      47.2 41.4 53.1\nH London                                               54.2 47.2 61.1\nJ South East                                           44.6 38.7 50.8\nK South West                                           46.5 39.4 53.8\nL Wales                                                38.6 27.7 50.7\nM Scotland                                             42.7 36.0 49.8\n\n\nQuestion 5\nWhat is the 95% confidence interval for the proportion of people interested in politics in the South West? Is the proportion likely to be different in London? In what way? What is the region of the UK for which the precision of the estimates is likely to be the smallest?\nWhen using svyby(), we can define domains or subpopulations with several variables, not just one. For example, we could have looked at gender differences in political affiliations by regions. However, as the size of subgroups decrease, so does the precision of the estimates as their confidence interval widens, to a point where their substantive interest is not meaningful anymore.\nQuestion 6\nUsing interest in politics as before, and three category age RAgecat5 (which you may want to recode as a factor in order to improve display clarity): \n- Produce a table of results showing the proportion of respondents significantly interested in Politics by age group\n- Assess whether the age difference in interest for politics is similar for each gender?\n- Based on the data, is it fair to say that men aged under 35 tend to be more likely to declare themselves interested in politics than women aged 55 and above?\n\n\nAnswers\nQuestion 1 The 2017 BSA is a three stage stratified random survey, with postcode sectors, adresses and individuals as the units selected at each stage. Primary sampling units were furthermore stratified according to geographies (sub regions), population density, and proportion of owner-occupiers. Sampling rate was proportional to the size of postcode sectors (ie number of addresses)\nQuestion 2 From the Data Dictionary it appears that the primary sampling units (sub regions) are identified bySpoint and the strata byStratID. The weights variable isWtFactor. Addresses are not provided but could be approximated with a household identifier.\nQuestion 3 Not using weights would make us overestimate the mean age in the population (of those aged 16+) by about 4 years. This is likely to be due to the fact that older respondents are more likely to take part to surveys. Using survey design variables does not alter the value of the estimated population mean. However, not accounting for them would lead us to overestimate the precision/underestimate the uncertainty of our estimate with a narrower confidence interval – by about plus and minus 2 months .\nQuestion 4 The proportion of 17-25 year old in the sample is 28.5 and its 95%confidence interval 26.5, 30.6\nQuestion 5 The 95% confidence interval for the proportion of people interested in politics in the South West is 39.4, 53.8. By contrast, it is likely to be 47.2, 61.1 in London. The region with the lowest precision of estimates (ie the widest confidence interval) is Wales, with a 23 percentage point difference between the upper and lower bounds of the confidence interval.\nQuestion 6\n\nbsa17$RAgecat5.f&lt;-as_factor(bsa17$RAgecat5)\nbsa17$Rsex.f&lt;-as_factor(bsa17$Rsex)\n\n\nbsa17.s&lt;-svydesign(ids=~Spoint, \n                   strata=~StratID, \n                   weights=~WtFactor,\n                   data=bsa17)\n\nround(\n      100*\n      svyby(~I(Politics.s==\"Significantly\"),\n            by=~RAgecat5.f+Rsex.f,\n            svyciprop,\n            design=bsa17.s,\n            vartype = \"ci\")[c(-8,-4),c(-2,-1)],\n      1)\n\n             I(Politics.s == \"Significantly\") ci_l ci_u\n17-34.Male                               42.9 37.7 48.2\n35-54.Male                               50.8 46.6 54.9\n55+.Male                                 57.8 53.9 61.6\n17-34.Female                             26.3 22.0 31.1\n35-54.Female                             34.1 30.6 37.8\n55+.Female                               43.0 39.6 46.5\n\n\nOlder respondents both male and female tend to be more involved in politics than younger ones.\nThe confidence intervals for the proportion of men under 35 and women above 55 interested in politics overlap; it is unlikely that they differ in the population.",
    "crumbs": [
      "R Exercises",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Using R with weights and survey design variables</span>"
    ]
  },
  {
    "objectID": "Population estimates using the BSAS with R.html",
    "href": "Population estimates using the BSAS with R.html",
    "title": "Basic population estimates with BSA data using R",
    "section": "",
    "text": "Getting started\nThis exercise is part of the ‘Introduction to the British Social Attitudes Survey (BSA)’ online module. In the exercise, we examine data from the 2020 British Social Attitudes survey to find out:\nAnswers to the questions asked throughout the exercise can be found at the end of the page.\nData can be downloaded from the UK Data Service website following registration. Download the compressed folder, unzip and save it somewhere accessible on your computer.\nThe examples below assume that the dataset has been saved in a new folder named UKDS on your Desktop (Windows computers). The path would typically be C:\\Users\\YOUR_USER_NAME\\Desktop\\UKDS. Feel free to change it to the location that best suits your needs.\nWe begin by loading the R packages needed for the exercise and set the working directory.\nlibrary(dplyr) ### Data manipulation functions\nlibrary(haven) ### Functions for importing data from \n               ### commercial packages\nlibrary(Hmisc) ### Extra statistical functions\n\n### Setting up the working directory\n### Please adjust the setwd() command  below   \n### to match the location of the data on your computer \n\nsetwd(\"C:\\Users\\Your_Username_here\\\")\n\ngetwd()\n[1] C:\\Users\\Your_Username_here\\\nWe then open the BSA dataset in SPSS format. Stata or tab-delimited format can also be used.\nbsa20&lt;-read_spss(\n       'UKDA-9005-spss/spss/spss25/bsa2020_archive.sav'\n       )",
    "crumbs": [
      "R Exercises",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic population estimates with BSA data using R</span>"
    ]
  },
  {
    "objectID": "Population estimates using the BSAS with R.html#appendix-recoding-nonresponses-as-system-missing-na",
    "href": "Population estimates using the BSAS with R.html#appendix-recoding-nonresponses-as-system-missing-na",
    "title": "Basic population estimates with BSA data using R",
    "section": "Appendix: recoding nonresponses as system missing (NA)",
    "text": "Appendix: recoding nonresponses as system missing (NA)\nThe code below provides and example of how to recode missing values into system missing (NA) using separate variables. For ease of interpretation, we also convert the original numeric variable into labelled factors using as_factor(), so that they directly display the value labels.\n\nbsa20&lt;-bsa20%&gt;%mutate(\n              TAXSPEND.r=factor(as_factor(TAXSPEND,\"labels\"), \n                                exclude = c(\"Prefer not to answer\",\n                                            \"Don't know\")),\n              EUVOTWHO.r=factor(as_factor(EUVOTWHO,\"labels\"),\n                                exclude = c(\"Prefer not to answer\",\n                                            \"I Don't remember\",\n                                            \"Not applicable\",NA)),\n              PenExp2.r=ifelse(PenExp2==-1 | PenExp2&gt;=9998,NA,PenExp2)\n                      )\n### Value labels need to be truncated as they are rather lengthy!\nlevels(bsa20$TAXSPEND.r)&lt;-substr(levels(bsa20$TAXSPEND.r),1,14)\nlevels(bsa20$EUVOTWHO.r)&lt;-substr(levels(bsa20$EUVOTWHO.r),1,6)\n\nlevels(bsa20$TAXSPEND.r)\n\n[1] \"Reduce taxes a\" \"Keep taxes and\" \"Increase taxes\"\n\nlevels(bsa20$EUVOTWHO.r)\n\n[1] \"Remain\" \"Leave \"",
    "crumbs": [
      "R Exercises",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic population estimates with BSA data using R</span>"
    ]
  },
  {
    "objectID": "infer_w_survey_design_usingSPSS.html",
    "href": "infer_w_survey_design_usingSPSS.html",
    "title": "Using SPSS with weights and survey design variables",
    "section": "",
    "text": "This exercise is part of the ‘Introduction to the British Social Attitudes Survey (BSA)’ online module. In this exercise, we will practice statistical inference with data from the British Social Attitudes Survey (BSA) 2017 using weights and survey design variables.\nPlease note that at the time of writing this document only some of the BSA editions include survey design variables. For more information about inference from social surveys, including cases where weights and/or survey design variables are not available, please consult our guidelines.\nAnswers to the questions asked throughout the exercise can be found at the end of the page.\n\nGetting started\nData can be downloaded from the UK Data Service website following registration. Download the compressed folder, unzip and save it somewhere accessible on your computer.\nThe examples below assume that the dataset has been saved in a new folder named UKDS on your Desktop (Windows computers). The path would typically be C:\\Users\\YOUR_USER_NAME\\Desktop\\UKDS. Feel free to change it to the location that best suits your needs\n\n\n1. Identifying the survey design and variables\nWe first need to find out about the survey design that was used in the BSA 2017, and the design variables available in the dataset. Such information can usually be found in the documentation that comes together with the data under the mrdoc/pdf folder or in the data catalogue pages for the data on the UK Data Service website.\nQuestion 1 What is the design that was used in this survey (ie how many stages were there, and what were the units sampled). What were the primary sampling units; the strata (if relevant)?\nNow that we are a bit more familiar with the way the survey was designed, we need to try and identify the design variables we can include when producing estimates. The information can usually be found in the user manual or the data dictionary available in the BSA documentation.\nQuestion 2 What survey design variables are available? Are there any that are missing – if so which ones? What is the name of the weights variables?\n\n\n2. Specifying the survey design\nLet us first open the 2017 BSA dataset.\nCD 'C:\\Users\\YOUR_USER_NAME\\Desktop\\UKDS'.\n  GET \n    FILE=' UKDA-8450-spss\\spss\\spss25\\bsa2017_for_ukda.sav'.\nIn principle, we should tell SPSS that we are working with a three stage stratified cluster sample. In practice however, we only have information about the initial ie primary sampling units.\nThis is achieved with the CSPLAN command through we create a plan file which contains the survey design information.\nCSPLAN ANALYSIS\n  /PLAN FILE='bsa17_SPSS_design.csaplan'\n  /PLANVARS ANALYSISWEIGHT=WtFactor       \n  /SRSESTIMATOR TYPE=WOR\n  /PRINT PLAN\n  /DESIGN STAGELABEL='S1' STRATA=StratID CLUSTER=Spoint \n  /ESTIMATOR TYPE=WR.\n\n\n3. Mean age and its 95% confidence interval\nWe can now produce a first set of estimates using this design and compare them with those we would have got without accounting for it. We will compute the average (ie mean) age of respondents in the sample, as well as the proportion of male and female respondents aged over 55. We will need to use /CSDESCRIPTIVES\nDATASET ACTIVATE DataSet1.\n* Complex Samples Descriptives.\nCSDESCRIPTIVES\n  /PLAN FILE='bsa17_SPSS_design.csaplan'\n  /SUMMARY VARIABLES=RAgeE\n  /MEAN\n  /STATISTICS SE CIN(95)\n  /MISSING SCOPE=ANALYSIS CLASSMISSING=EXCLUDE.\n\nUnder the /STATISTICS command we can request either or both the standard error of the mean and its 95% confidence interval.\nWhat difference would it make to the estimates and 95% CI to compute respectively, an unweighted mean, as well as a weighted mean without accounting for the survey design?\nUnweighted means and CI\nDESCRIPTIVES VARIABLES=RAgeE\n  /STATISTICS=MEAN SEMEAN.\nSPSS does not provide an option for computing confidence intervals in this case, but we know that a 95% confidence interval is the sample mean respectively minus and plus 1.96 times its standard error. Using the SPSS output, we can compute it ourselves as 1.96*.2872=about .56 years, that is close to 7 months.\nWeighted means and CI without survey design\nWEIGHT BY WtFactor.\nDESCRIPTIVES VARIABLES=RAgeE\n  /STATISTICS=MEAN SEMEAN.\nWEIGHT OFF.\nQuestion 3 What are the consequences of weighing but not accounting for the sample design; not using weights and accounting for the sample design when:\n\ninferring the mean value of the population age?\ninferring the uncertainty of our estimate of the population age?\n\n\n\n4. Computing a proportion and its 95% confidence interval\nWe can now similarly compute an estimate of a proportion (or percentage) of a categorical variable in the population. For instance, the proportion of people who declare themselves interested in politics. This is the Politics variable. It has five categories that we are going to recode into ‘Significantly’ (interested) and ‘Not’ (significantly) in order to simplify the analysis.\nThe BSA regards ‘don’t know’ and ‘refusal’ responses as valid but since in this case there is only one ‘don’t know’ and no ‘refusal’, we can safely ignore these categories and recode them as system missing.\nFREQUENCIES VARIABLES=Politics\n  /ORDER=ANALYSIS.\n\nRECODE Politics (9=SYSMIS) (1 thru 2=1) (3 thru 5=2) INTO Politics.s.\nEXECUTE.\n\nVARIABLE LABELS\nPolitics.s   \"Whether significantly interested in politics\".\nVALUE LABELS\nPolitics.s\n1  \"Significant\"\n2  \"Not significant\". \nEXECUTE.\n\nFREQUENCIES VARIABLES=Politics.s\n  /ORDER=ANALYSIS.\n\nWEIGHT BY WtFactor.\nFREQUENCIES VARIABLES=Politics.s\n  /ORDER=ANALYSIS.\nWEIGHT OFF.\nAs with the mean of age earlier, we can see that the weighted and unweighted point estimates of the proportion of respondents significantly interested in politics change, even if slightly, and that they remain the same when survey design is accounted for.\nWith the help of CSTABULATE we can examine frequencies, proportions and confidence intervals of these proportions accounting for the survey design. As before, the point estimates do not further change once survey design is accounted for.\n* Complex Samples Frequencies.\nCSTABULATE\n  /PLAN FILE='bsa17_SPSS_design.csaplan'\n  /TABLES VARIABLES=Politics.s\n  /CELLS POPSIZE TABLEPCT\n  /STATISTICS CIN(95) \n  /MISSING SCOPE=TABLE CLASSMISSING=EXCLUDE.\nQuestion 4 What is the proportion of respondents aged 17-34 in the sample, as well as its 95% confidence interval? You can use RAgecat5\n\n\n5. Domain (ie subpopulation) estimates\nAlthough computing estimates for specific groups (for example the average age of people who report being interested in politics) is not conceptually different from doing it for the sample as a whole, doing it with weights as part of an inferential analysis requires some caution. Calculating weighted estimates for a subpopulation while the rest of the sample is left out of the analysis might yield incorrect results. This is why using survey design informed functions is particularly recommended when doing such analyses.\nThe SPSS command CSDESCRIPTIVES that we used above makes such domain estimation relatively straightforward. If we would like to compute the mean age of BSA respondents by government office regions, we need to specify:\n\nThe outcome variable whose estimate we want to compute: ie RAgeE\nThe grouping variable(s) GOR_ID\nAnd the type of type of variance estimation we would like to see displayed ie standard errors or confidence interval\n\n * Complex Samples Descriptives.\nCSDESCRIPTIVES\n  /PLAN FILE='bsa17_SPSS_design.csaplan'\n  /SUMMARY VARIABLES=RAgeE\n  /SUBPOP TABLE=GOR_ID DISPLAY=LAYERED\n  /MEAN\n  /STATISTICS CIN(95)\n  /MISSING SCOPE=ANALYSIS CLASSMISSING=EXCLUDE.\n\nOur inference seem to suggest that the population in London is among the youngest in the country, and that those in the South West are among the oldest – their respective 95% confidence intervals do not overlap. We should not feel so confident about differences between London and the South East for example, as the CIs partially overlap.\nWe can also examine proportions for subpopulations. In order to do this, we need to specify the category of the variable we are interested in as an outcome.For instance, the syntax below uses respondents who are significantly interested in politics:\n* Complex Samples Frequencies.\nCSTABULATE\n  /PLAN FILE='bsa17_SPSS_design.csaplan'\n  /TABLES VARIABLES=Politics.s\n  /SUBPOP TABLE=GOR_ID DISPLAY=LAYERED\n  /CELLS TABLEPCT\n  /STATISTICS CIN(95) \n  /MISSING SCOPE=TABLE CLASSMISSING=EXCLUDE.\nQuestion 5 What is the 95% confidence interval for the proportion of people interested in politics in the South West? Is the proportion likely to be different in London? In what way? What is the region of the UK for which the precision of the estimates is likely to be the smallest?\nWhen using CSTABULATE, we can define domains or subpopulations with several variables, not just one. For example, we could look at gender differences in political affiliations by regions. However, as the size of subgroups decrease, so does the precision of the estimates as their confidence interval widens, to a point where their substantive interest is not meaningful anymore.\nQuestion 6 Using interest in politics as before, and three category age RAgecat5:\n\nProduce a table of results showing the proportion of respondents significantly interested in Politics by age group and gender\nAssess whether the age difference in interest for politics is similar for each gender?\nBased on the data, is it fair to say that men aged under 35 tend to be more likely to declare themselves interested in politics than women aged 55 and above?\n\n\n\nAnswers\nQuestion 1 The 2017 BSA is a three stage stratified random survey, with postcode sectors, adresses and individuals as the units selected at each stage. Primary sampling units were stratified according to geographies (sub regions), population density, and proportion of owner-occupiers. Sampling rate was proportional to the size of postcode sectors (ie number of addresses).\nQuestion 2 From the Data Dictionary it appears that the primary sampling units (sub regions) are identified by Spoint and the strata by StratID. The weights variable is WtFactor. Addresses are not provided but could be approximated with a household identifier.\nQuestion 3 Not using weights would make us overestimate the mean age in the population (of those aged 16+) by about 4 years. This is likely to be due to the fact that older respondents are more likely to take part to surveys. Using survey design variables does not alter the value of the estimated population mean. However, not accounting for it would lead us to overestimate the precision/underestimate the uncertainty of our estimate with a narrower confidence interval – by about plus or minus 3 months.\nQuestion 4 The proportion of 17-34 year old in the sample is 28.5 and its 95% confidence interval 26.5, 30.6\nQuestion 5 The 95% confidence interval for the proportion of people interested in politics in the South West is 39.8-53.4. By contrast, it is 47.6-60.8 in London. The region with the lowest precision of estimates (ie the widest confidence interval) is Wales, with a 20 percentage point difference between the upper and lower bounds of the confidence interval.\nQuestion 6\nCSTABULATE\n  /PLAN FILE='bsa17_SPSS_design.csaplan'\n  /TABLES VARIABLES=Politics.s\n  /SUBPOP TABLE=Rsex BY RAgecat5 DISPLAY=LAYERED\n  /CELLS TABLEPCT\n  /STATISTICS CIN(95) \n  /MISSING SCOPE=TABLE CLASSMISSING=EXCLUDE.\n\n\n\nSPSS output for POLITICS.s by Rsex and RAgecat5\n\n\nOlder respondents both male and female tend to be more involved in politics than younger ones.\nThe confidence intervals for the proportion of men under 35 and women above 55 interested in politics overlap; it is unlikely that they differ in the population.",
    "crumbs": [
      "SPSS Exercises",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Using SPSS with weights and survey design variables</span>"
    ]
  },
  {
    "objectID": "Pop_estimates_using_the_BSAS_and_SPSS.html",
    "href": "Pop_estimates_using_the_BSAS_and_SPSS.html",
    "title": "Basic population estimates with BSA data using SPSS",
    "section": "",
    "text": "Getting started\nThis exercise is part of the ‘Introduction to the British Social Attitudes Survey (BSA)’ online module. In the exercise, we examine data from the 2020 British Social Attitudes survey to find out:\nAnswers to the questions asked throughout the exercise can be found at the end of the page.\nData can be downloaded from the UK Data Service website following registration. Download the compressed folder, unzip and save it somewhere accessible on your computer.\nThe examples below assume that the dataset has been saved in a new folder named UKDS on your Desktop (Windows computers). The path would typically be C:\\Users\\YOUR_USER_NAME\\Desktop\\UKDS. Feel free to change it to the location that best suits your needs.\nYou need to set the folder as your working directory in SPSS. To do this, you need to add the correct file path to the folder on your computer to the code below.\nIf you have your working directory saved to the folder location, the following code should open the BSA dataset.",
    "crumbs": [
      "SPSS Exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Basic population estimates with BSA data using SPSS</span>"
    ]
  },
  {
    "objectID": "Pop_estimates_using_the_BSAS_and_SPSS.html#appendix-recoding-nonresponses-as-system-missing",
    "href": "Pop_estimates_using_the_BSAS_and_SPSS.html#appendix-recoding-nonresponses-as-system-missing",
    "title": "Basic population estimates with BSA data using SPSS",
    "section": "Appendix: recoding nonresponses as system missing",
    "text": "Appendix: recoding nonresponses as system missing\nThe code below provides and example of how to recode missing values including ‘don’t knows’ and ‘prefer not to say’ into system missing.\nThe SPSS syntax below includes the command, the variables and the relevant missing values in (). Note, you can set missing values more than 1 at a time if they have the same missing value pattern.\nCOMPUTE EUVOTWHO_m=EUVOTWHO.\nCOMPUTE TAXSPEND_m=TAXSPEND.\nCOMPUTE PenExp2_m=PenExp2.\n\nMISSING VALUES PenExp2_m (-1, 9998, 9999). \nMISSING VALUES TAXSPEND_m (-1, 8, 9). \nMISSING VALUES EUVOTWHO_m (-1, 3 THRU 9).",
    "crumbs": [
      "SPSS Exercises",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Basic population estimates with BSA data using SPSS</span>"
    ]
  }
]